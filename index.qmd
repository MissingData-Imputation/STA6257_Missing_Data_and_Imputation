---
title: "Missing Data and Imputation"
author:
  - Javier Estrada
  - Michael Underwood
  - Elizabeth Subject-Scott
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
    code-tools: true
    css: styles.css
    theme: morph
    toc: true
    toc-location: left
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
editor: 
  markdown: 
    wrap: 72
---

[Website](https://missingdata-imputation.github.io/STA6257_Missing_Data_and_Imputation/)

[Slides](https://rstudio.hmcse.uwf.edu/s/4c3307ed3545b19414f79/files/STA6257_Missing_Data_and_Imputation/Slides.html#/title-slide)

## Introduction

#### What is missing data?

Missing data occurs when there are missing values in a dataset. There
are many reasons why this occurs. It can be intentional or unintentional
and can be classified into the following three categories, otherwise
known as missingness mechanisms [@mai2023]:

-   Missing completely at random (MCAR) is the probability of missing
    data being completely independent of any other variables.

-   Missing at random (MAR) is the probability of missing data being
    related to the observed values.

-   Missing not at random (MNAR) is the probability of missing data
    being dependent on the missing and observed values.

![](GraphicalRepresentation.png)

Figure 1: Graphical Representation of Missingness Mechanisms [@sch2002]

(X are the completely observed variables. Y are the partly missing
variables. Z is the component of the cause of missingness unrelated to X
and Y. R is the missingness.)

Looking for patterns in the missing data can help us to determine to
which category they belong. These mechanisms are important in
determining how to handle the missing data. MCAR would be the best case
scenario but seldom occur. MAR and MNAR are more common.

The problem with ignoring any missing values is that it does not give a
true representation of the dataset and can lead to bias when analyzing.
This reduces the statistical power of the analysis [@van2020]. To
enhance the quality of the research, the following should be followed:
explicitly acknowledge missing data problems and the conditions under
which they occur and employ principled methods to handle the missing
data [@don2013].

There are three types of methods to deal with missing data, the
likelihood and Bayesian method, weighting methods, or imputation methods
[@cao2021]. Missing data can also be handled by simply deleting.

#### Likelihood Bayesian Method

#### Weighting Method

#### Deleting missing data

Listwise deletion is when the entire observation is removed from the
dataset. Deleting missing data can lead to the loss of important
information regarding your dataset and is therefore not recommended. In
certain cases, when the amount of missing data is small and the type is
MCAR, listwise deletion can be used. There usually won't be bias but
potentially important information may be lost.

T-tests and chi-square tests can be used to assess pairs of predictor
variables to determine whether the groups' means differ significantly.
According to [@van2020], if significant, the null hypothesis is
rejected, therefore, indicating that the missing values are not randomly
scattered throughout the data. This implies that the missing data is MAR
or MNAR. Conversely, if nonsignificant, this implies that the data
cannot be MAR. This does not eliminate the possibility that it is not
MNAR--other information about the population is needed to determine
this. Whenever missing data is categorized as MAR or MNAR, listwise
deletion would be wasteful, and the analysis biased. Alternate methods
of dealing with the missing data is recommended: either pairwise
deletion or imputation.

Pairwise deletion is when only the missing variable of an observation is
removed. It allows more data to be analyzed than listwise deletion but
limits the ability to make inferences of the total sample. For this
reason, it is recommended to use imputation to properly deal with
missing data.

#### What is imputation?

Imputation is the method of replacing missing data with an estimate
obtained from the original, available data so there is a full data set
to analyze. To improve statistical power, the number of imputations
created should be at least equal to the percent of missing data (5%
equals 5 imputations, 10% equals 10 imputations, 20% equals 20
imputations, etc.) [@ped2017]. There are two types of imputation: single
and multiple.

#### Single Imputation

Single, or univariate, imputation is when only one estimate is used to
replace the missing data. Methods of single imputation include using the
mean, the last observation carried forward, and random imputation. The
following is a brief explanation of each:

-   Using the mean to replace a missing value is a straight-forward
    process. The mean of the dataset is calculated, including the
    missing value. The mean is then multiplied by the number of
    observations in the study. Next, the known values are subtracted
    from the product, and this gives an estimate that can be used for
    any missing values. The problem with this method is that it reduces
    the variance which leads to a smaller confidence interval.

-   Last Observation Carried Forward (LOCF) is a technique of replacing
    a missing value in longitudinal studies with a previously observed
    value (the most recent value is carried forward) [@str2008]. The
    problem with this method is that it assumes that the previous
    observed value is perpetual when in reality that most likely is not
    the case.

-   Random imputation is a method of randomly drawing an observation and
    using that observation for any of the missing values. The problem
    with this method is that it introduces additional variability.

These single imputation methods are flawed. They often result in
underestimation of standard errors or too small p-values [@don2013],
which can cause bias in the analysis. Therefore, multiple imputation is
the better method because it handles missing data better and provides
less biased results.

#### Multiple Imputation

Multiple, or multivariate, imputation is when various estimates are used
to replace the missing data by creating multiple datasets from versions
of the original dataset. It can be done by using a regression model, or
a sequence of regression models, such as linear, logistic and Poison. A
set of *m* plausible values are generated for each unobserved data
point, resulting in *m* complete data sets [@don2013]. The new values
are randomly drawn from predictive distributions either through joint
modeling (JM, which is not used much anymore) or fully conditional
specification (FCS) [@won2023]. It is then analyzed and the results are
combined to obtain a single value for the missing data.

The purpose of multiple imputation is to create a pool of imputed data
for analysis, but if the pooled results are lacking, then multiple
imputation should not be done [@mai2023]. Another reason not to use
multiple imputation is if there are very few missing values; there may
be no benefit in using it. Also worth noting is some statistical
analyses software already have built-in features to deal with missing
data.

Multiple imputation by chained methods, otherwise known as MICE, is the
most common and preferred, method of multiple imputation [@wul2017]. It provides a more reliable way to analyze data with missing
values. For this reason, this paper will focus on the methodology and
application of the MICE process.

```{r, warning=FALSE, echo=T, message=FALSE}
#loading packages
library(DiagrammeR)
```

Figure 2: Flowchart of the MICE-process based on procedures proposed by
Rubin [@wul2017]

```{r, warning=FALSE, echo=T, message=FALSE}
DiagrammeR::grViz("digraph {

# initiate graph
graph [layout = dot, rankdir = LR, label = 'The MICE-Process\n\n',labelloc = t, fontcolor = DarkSlateBlue, fontsize = 45]

# global node settings
node [shape = rectangle, style = filled, fillcolor = AliceBlue, fontcolor = DarkSlateBlue, fontsize = 35]
bgcolor = none

# label nodes
incomplete [label =  'Incomplete data set']
imputed1 [label = 'Imputed \n data set 1']
estimates1 [label = 'Estimates from \n analysis 1']
rubin [label = 'Rubin rules', shape = diamond]
combined [label = 'Combined results']
imputed2 [label = 'Imputed \n data set 2']
estimates2 [label = 'Estimates from \n analysis 2']
imputedm [label = 'Imputed \n data set m']
estimatesm [label = 'Estimates from \n anaalysis m']


# edge definitions with the node IDs
incomplete -> imputed1 [arrowhead = vee, color = DarkSlateBlue]
imputed1 -> estimates1 [arrowhead = vee, color = DarkSlateBlue]
estimates1 -> rubin [arrowhead = vee, color = DarkSlateBlue]
incomplete -> imputed2 [arrowhead = vee, color = DarkSlateBlue]
imputed2 -> estimates2 [arrowhead = vee, color = DarkSlateBlue]
estimates2-> rubin [arrowhead = vee, color = DarkSlateBlue]
incomplete -> imputedm [arrowhead = vee, color = DarkSlateBlue]
imputedm -> estimatesm [arrowhead = vee, color = DarkSlateBlue]
estimatesm -> rubin [arrowhead = vee, color = DarkSlateBlue]
rubin -> combined [arrowhead = vee, color = DarkSlateBlue]
}")
```

#### Other Methods of Imputation

There are other methods of imputation worth noting and are briefly descrbied below.

*Regression Imputation* is based on a linear regression model. Missing
data is randomly drawn from a conditional distribution when variables
are continuous and from a logistic regression model when they are
categorical [@van2020].

*Predictive Mean Matching* is also based on a linear regression model.
The approach is the same as regression imputation when it comes to
categorical missing values but different for continuous variables.
Instead of random draws from a conditional distribution, missing values
are based on predicted values of the outcome variable [@van2020].

*Hot Deck (HD)* imputation is when a missing value is replaced by an
observed response of a similar unit, also known as the donor. It can be
either random or deterministic (based on a metric or value) [@tho2022].
It does not rely on model fitting.

*Stochastic Regression (SR) Imputation* is an extension of regression
imputation. The process is the same but a residual term from the normal
distribution of the regression of the predictor outcome is added to the
imputed value [@tho2022]. This maintains the variability of the data.

*Random Forest (RF) Imputation* is based on machine learning algorithms.
Missing values are first replaced with the mean or mode of that
particular variable and then the dataset is split into a training set
and a prediction set [@tho2022]. The missing values are then replaced
with predictions from these sets. This type of imputation can be used on
continuous or categorical variables with complex interactions.

## Methodology

**Multiple Imputation by Chained Equations (MICE)**

In multiple imputation, *m* imputed values are created for each of the
missing data and result in *m* complete datasets. For each of the *m*
datasets, an estimate of $\theta$ is acquired.

Combined estimator of $\theta$ is given by:

${\hat{\theta}}_{M}$=$\displaystyle \frac{1}{M}$$\sum_{m = 1}^{M} {\hat{\theta}}_{m}$

The proposed variance estimator of ${\hat{\theta}}_{M}$ is given by:

${\hat{\Phi}}_{M}$ =
${\overline{\phi}}_{M}$+(1+$\displaystyle \frac{1}{M}$)*B*$_{M}$

where ${\overline{\phi}}_{M}$ =
$\displaystyle \frac{1}{M}$$\sum_{m = 1}^{M}$${\hat{\phi}}_m$

and B$_{M}$ =
$\displaystyle \frac{1}{M-1}$$\sum_{m = 1}^{M}$(${\hat{\theta}}_{m}$-${\overline{\theta}}_{M}$)$^{2}$

[@arn2017]

```{r, warning=FALSE, echo=T, message=FALSE}
# credit[is.na(credit) | credit=="Inf"] = NA
# lm(Amount ~ Seniority + Home + Time + Age + Marital + Records + Job + Expenses + Income + Assets + Debt + Seniority + Price, data = credit)
# credit_model = lm(formula = Amount ~ Seniority + Home + Time + Age + Marital + Records + Job + Expenses + Income + Assets + Debt + Seniority + Price, data = credit)
```

The chained equation process has the following steps [@azu2011]:

##### Step 1:

Using simple imputation, replace the missing data with this value,
referred to as the "place holder".

##### Step 2:

The "place holder" values for one variable are set back to missing.

##### Step 3:

The observed values from this variable (dependent variable) are
regressed on the other variables (independent variables) in the model,
using the same assumptions when performing linear, logistic, or Poison
regression.

##### Step 4:

The missing values are replaced with predictions "m" from this newly
created model.

##### Step 5:

Repeat Steps 2-4 for each variable that have missing values until all
missing values have been replaced.

##### Step 6:

Repeat Steps 2-4, updating imputations each cycle for as many "m"
cycles/imputations that are required.

Average the estimates across m estimates. Calculate the standard errors
and variance of m estimates. Combine using an adjustment term (1+1/m).

## Analysis and Results

## Data and Visualization

```{r, warning=FALSE, echo=T, message=FALSE}
# load data
credit = read.csv("credit_data.csv")

# load packages
library(gtsummary)
```

##### Description of Data

Credit score data

##### Details of Data

The credit.csv file is from the website of Dr. Lluís A. Belanche Muñoz,
by way of a github repository of Dr. Gaston Sanchez. It contains data of
4,454 subjects and stores a combination of continuous, categorical and
count values for 15 variables. Of the 15 variables, the "Status"
variable contains binomial categorical values of "good" and "bad" to
describe the kind of credit score each subject has. One data point is
missing an outcome and was removed from the original data.

| Variable  | Type      | Description                                                                                                                                    |
|----------------|----------------|----------------------------------------|
| X         | Integer   | Count variable indicating the number of subjects.                                                                                              |
| Status    | Character | 2-level categorical variable indicating the status of the subject's credit: good or bad.                                                       |
| Seniority | Integer   | Count variable indicating the seniority a subject has accumulated over the course of their life.                                               |
| Home      | Character | 6-level categorical variable indicating the subject's relationship to their residential address: rent, owner, parents, priv, other, or ignore. |
| Time      | Integer   | Count variable showing how many months has elapsed since the subject's payment deadline without paying their debt full.                        |
| Age       | Integer   | Count variable indicating subject's age (in years).                                                                                            |
| Marital   | Character | 5-level categorical variable indicating the subject's marital status: single, married, separated, divorced, or widow.                          |
| Records   | Character | 2-level categorical variable indicating whether the subject has a credit history record: yes or no.                                            |
| Job       | Character | 4-level categorical variable indicating the type of job the subject has: fixed, freelance, partime, or others.                                 |
| Expenses  | Integer   | Count variable indicating the amount of expenses (in USD) a subject has.                                                                       |
| Income    | Integer   | Count variable indicating the amount of income (in thousands of USD) a subject earns annually.                                                 |
| Assets    | Integer   | Count variable indicating the amount of assets (in USD) a subject has.                                                                         |
| Debt      | Integer   | Count variable indicating the amount of debt (in USD) a subject has.                                                                           |
| Amount    | Integer   | Count variable indicating the amount of money (in USD) remaining in a subject's bank account.                                                  |
| Price     | Integer   | Count variable indicating the amount of money a subject earns by the end of the month.                                                         |

##### Summary of Data:

```{r, warning=FALSE, echo=T, message=FALSE}
credit %>%
  tbl_summary(by = Status,
              missing_text = "NA") %>%
  add_p() %>%
  add_n() %>%
  add_overall %>%
  modify_header(label ~ "**Variable**") %>%
  modify_caption("**Summary of Credit Data**") %>%
  bold_labels()
```

As indicated in the table, the data contains NA/missing values. In order to conduct analysis, we need to delete the missing data. We will create a new dataset with the deleted values. 

```{r}
library(dplyr)
library(mice)

new_credit = na.omit(credit) 
summary(new_credit)

credit_lm = lm(Amount ~ Status + Seniority + Home + Time + Age + Marital + Records + Job + Expenses + Income + Assets + Debt + Price, data=new_credit)
```

415 rows were deleted due to missing values. In order to conduct regression, we must throw away 9.3% of our data because of missingness. We can use the mice package in R to impute the missing values so that we don't have to discard such valuable information.

It's a good idea to check distribution before and after imputation to
make sure the distribution doesn't change significantly. When
categorical data is missing, the mode can be used for the missing
points. If there is a large amount of missing categorical data, then it
should be removed and a new category should be used.

```{r, warning=FALSE, echo=T, message=FALSE}
# load library
library(mice, warn.conflicts=FALSE)
library(ggplot2)
library(dplyr, warn.conflicts=FALSE)
library(cowplot)

# credit$Amount
# 
# ggplot(credit, aes(Amount, fill = credit, color = credit)) +
#   geom_histogram(color = "#000000", fill = "#0099F8") +
#   ggtitle("Variable distribution") +
#   theme_classic() +
#   theme(plot.title = element_text(size = 18))
# 
# # TRANSFORM TO LONG DATA FOR PLOTS
# credit.Long<- credit %>% pivot_longer(!y, names_to="credit", values_to="score", values_transform=list(score=as.numeric))
# 
# # HISTOGRAMS
# ggplot(credit, aes(Amount, fill=credit, color=credit)) +
#   geom_histogram(alpha=0.2, breaks=seq(0,5,1)) +
#   lemon::facet_rep_wrap(.~credit, nrow=2, labeller="label_both", repeat.tick.labels=T) +
#   labs(title="Distributions of Raw Score") +
#   theme_bw() +
#   theme(legend.position = "none",
#         panel.border = element_rect(color = "#8B814C"),
#         strip.background = element_rect(fill = "#EAEAD6", color = "#8B814C"),
#         strip.text = element_text(color = "#8B814C", size=14),
#         plot.background = element_rect(fill = "#FAFAF5"),
#         axis.text = element_text(color = "#8B814C"),
#         axis.title = element_text(color = "#8B814C", size=14),
#         plot.title = element_text(color = "#8B814C", size=14),
#         axis.ticks = element_line(color = "#8B814C"))
```

Before imputing the missing data, it is important to check whether the
data has a linear relationship. Nonlinear data should be accounted for
in the analysis as well as the imputation process. Otherwise, an
incorrect statistical model will result. Also, it is a good idea to
check the distribution before and after imputing to make sure there are
no drastic changes. Also, need to verify the missingess mechanism.
Before imputing, you need to determine how many imputations are needed.
3-5 imputations are sufficient, and 10 are more than enough [@wul2017].
It is also important to check for anomalies that may occur during
imputation. Imputation models may need to be adjusted if the imputed
values fall outside the minimum and maximum range of the observed
values. More or fewer variables in the imputation model may be needed
for these types of anomalies. After imputation compute wald test
statistic to test interactions. Always need to disclose method used to
replace missing values when analyzing data.

We created 5 datasets with imputed values using the MICE package
(Multivariate Imputation by Chained Equations) in R, a statistical
programming software. It seamlessly imputes missing values in a dataset
by looking at the data from other columns and estimate the best
prediction for each missing value.

```{r, warning=FALSE, echo=T, message=FALSE}
data <- credit[-c(1,4,7,8,9)]
# summary(data)

md.pattern(data)

pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(data,2,pMiss)
# apply(data,1,pMiss)
```

The following variables are missing data:

Income NA's: 381/4454 = 8.6%

Assets NA's: 47/4454 = 1.1%

Debt NA's: 18/4454 = 0.4%

We need to determine the missingness mechanism for each. We can do this
in R using the mice package. There is a function that will help us
determine the pattern of missing data: md.pattern().

4,039 samples are complete

```{r, warning=FALSE, echo=T, message=FALSE}
# load library
library(VIM)

aggr_plot <- aggr(data, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE, labels=names(credit), cex.axis=.7, gap=3, ylab=c("Histogram of missing data","Pattern"))

marginplot(data[c(1,2)])

methods(mice)

```

```{r, warning=FALSE, echo=T, message=FALSE}
# load libraries
library('mice')
library('tidyverse')

#summary(credit)
```

This contains a subset of the credit data where the rows having missing
value.

```{r, warning=FALSE, echo=T, message=FALSE}
rows_na = credit[!complete.cases(credit),]  

head(rows_na, 10)
```

This shows a matrix where each row corresponds to a missing data pattern
in the credit data set.

```{r, warning=FALSE, echo=T, message=FALSE}
md.pattern(credit)

```

In order to perform multiple imputation on categorical data, all string
variables must be converted to \# factors using as.factor()

```{r, warning=FALSE, echo=T, message=FALSE}
credit$Status = as.factor(credit$Status)
credit$Home = as.factor(credit$Home)
credit$Marital = as.factor(credit$Marital)
credit$Records = as.factor(credit$Records)
credit$Job = as.factor(credit$Job)
```

Using the mice() function, 5 (default) multiple imputations for the null
values for the credit data \# will be generated.

```{r, warning=FALSE, echo=T, message=FALSE}
Multiple_Imputation = mice(data = credit,  defaultMethod = c("pmm", "logreg", "polyreg", "polr"), set.seed = 1337)
```

Show the imputed values. Columns are imputations, rows are observations

```{r, warning=FALSE, echo=T, message=FALSE}
Multiple_Imputation$imp
```

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(ggplot2)
library(ggfortify)

# library(knitr)
# library(ggthemes)
# library(ggrepel)
# library(dslabs)
```

```{r, warning=FALSE, echo=T, message=FALSE}
# model1=lm(Amount~Status+Seniority+Home+Time+Age+Marital+Records+Job+Expenses+Income+Assets+Debt+Price, data=credit)
# autoplot(model1)
# 
# ggplot1 = credit %>% ggplot(mapping = aes(x=population/10^6, y=total)) 
# 
#   ggplot1 + geom_point(aes(col=region), size = 4) +
#   geom_text_repel(aes(label=abb)) +
#   scale_x_log10() +
#   scale_y_log10() +
#   geom_smooth(formula = "y~x", method=lm,se = F)+
#   xlab("Populations in millions (log10 scale)") + 
#   ylab("Total number of murders (log10 scale)") +
#   ggtitle("US Gun Murders in 2010") +
#   scale_color_discrete(name = "Region")+
#       theme_wsj()
```

## Statistical Modeling

## Conclusion

In conclusion, missing data can occur in research for a variety of
reasons. It is never a good idea to ignore it. Doing this will lead to
biased estimates of parameters, loss of information, decreased
statistical power, and weak reliability of findings [@don2013]. The best
course of action is to impute the missing data by using multiple
imputation. When missing data is discovered, it is important to first
identify it and look for missing data patterns. Next, define the
variables in the dataset that are related to the missing values that
will be used for imputation. Create the necessary number of complete
data sets. Run the models and combine them using the imputed values, and
finally, analyze the complete dataset. Performing these steps will
minimize the adverse effects caused by missing data on the anaylsis
[@pam2016].
